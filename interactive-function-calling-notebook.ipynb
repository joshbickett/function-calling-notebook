{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 🛠️ **Interactive OpenAI Function Calling Tutorial** \n",
    "\n",
    "Learn by doing! This interactive tutorial walks you through creating a function, and then lets you chat with an assistant to use it.\n",
    "\n",
    "Get an intuitive understanding of Function Calling in under 5 minutes!\n",
    "\n",
    "---\n",
    "\n",
    "## **What is Function Calling?**\n",
    "\n",
    "Function calling is a powerful feature that enables a ChatGPT assistant to *act*. By defining specific abilities (or functions), you grant the assistant the capability to perform them based on a user's request.\n",
    "\n",
    "---\n",
    "\n",
    "## **What to Expect in this Notebook**\n",
    "\n",
    "In this notebook, we'll look at examples to understand how function calling works:\n",
    "\n",
    "1. 🎈 **Simple Example:** Balloon launch function\n",
    "2. 🌦️ **Advanced Example:** Fetch weather info function\n",
    "\n",
    "---\n",
    "\n",
    "### **About**\n",
    "👤 **Creator:** [Josh Bickett](https://twitter.com/josh_bickett)\n",
    "\n",
    "📘 **Colab:** [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/joshbickett/function-calling-notebook/blob/main/interactive-function-calling-notebook.ipynb)\n",
    "\n",
    "🔗 **Github:** [View on GitHub](https://github.com/joshbickett/function-calling-notebook)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the OpenAI Library\n",
    "\n",
    "Run the code below to install the `openai` library, which lets us interact with OpenAI's platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "In this section, we will import the necessary libraries to make our function work smoothly. Among them, you'll notice the `'YOUR_API_KEY'` placeholder. \n",
    "\n",
    "To use the OpenAI platform, you need to replace `'YOUR_API_KEY'` with your actual OpenAI API key. If you don't have one, you can obtain an OpenAI key [here](https://platform.openai.com/account/api-keys).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import random\n",
    "\n",
    "openai.api_key = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Launching a Water Balloon 🎈💦\n",
    "\n",
    "This is a playful function we've built for demonstration. It simulates launching a water balloon of a given size and then randomly decides where the balloon hits. Will it be the ground, a tree, or even the moon? Let's find out!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def launch_water_balloon(balloon_size):\n",
    "    hit_locations = ['the ground', 'a tree', 'the moon']\n",
    "    random_location = random.choice(hit_locations)\n",
    "    launch_results = f'Launching the {balloon_size} water balloon, it hit {random_location}!'\n",
    "    return launch_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Function for ChatGPT 🤖\n",
    "\n",
    "After defining our function, we need to create a `functions` list variable. This list will be passed to OpenAI's `ChatCompletion.create` method, letting the assistant know what \"abilities\" it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"launch_water_balloon\",\n",
    "        \"description\": \"This function launches a hypothetical water balloon\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"balloon_size\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Large\", \"Medium\", \"Small\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"balloon_size\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "available_functions = {\n",
    "    \"launch_water_balloon\": launch_water_balloon,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the \"Chat Environment\" 🤖➡️🛠️\n",
    "\n",
    "Below, we define `converse` to send the user's message to the OpenAI API, including information about our previously created water balloon launcher function.\n",
    "\n",
    "The code `response_message.get(\"function_call\")` checks if the `response_message` is a function calling response. If it is, then the assistant is requesting to use a function, such as the balloon launcher, instead of replying to the user with a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def converse(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    \n",
    "    messages.append(response_message) \n",
    "    if response_message.get(\"function_call\"):\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "\n",
    "        print('[inspector] Oh, we got a function call! 🔨')\n",
    "        print('[inspector] ===> function_name', function_name)\n",
    "        print('[inspector] ===> function_args', function_args)\n",
    "        function_response = function_to_call(\n",
    "            balloon_size=function_args.get(\"balloon_size\"),\n",
    "        )\n",
    "\n",
    "        print('[inspector] ===> function_response', function_response)\n",
    "\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print('Assistant: ', function_response)\n",
    "        \n",
    "    else: \n",
    "        content = response_message.get(\"content\")\n",
    "        print('Assistant: ', content)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we're ready, let's chat with ChatGPT! 🎉\n",
    "\n",
    "Now that everything's set up, it's time to start a conversation.\n",
    "\n",
    "Simply run the code cell and type your message, and the Assistant will respond, potentially even launching a water balloon or two! 😄\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "message_count = 0 \n",
    "while message_count < 10: \n",
    "    user_input = input(\"User: \")\n",
    "    user_message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages.append(user_message)\n",
    "    converse(messages)\n",
    "    message_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Fetching Tonight's Weather 🌙☁️\n",
    "\n",
    "This function is a step up from our playful balloon launch, diving into the practical use case of fetching weather data for major US cities.\n",
    "\n",
    "We have a predefined list of cities with their coordinates. When given a city name:\n",
    "1. The function first locates the city within our list.\n",
    "2. Using the city's coordinates, it queries the National Weather Service's API for the weather forecast.\n",
    "3. It then extracts and returns the detailed forecast for tonight from the data received.\n",
    "\n",
    "Want to know if it's a good night for stargazing in San Francisco or if you should carry an umbrella in New York City? Just ask, and let ChatGPT fetch the weather details for you!\n",
    "\n",
    "\n",
    "##### ***Important note***:\n",
    "You have to stop the last cell in order to continue because it continues running since it is a conversation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cities = [\n",
    "    {\"name\": \"San Francisco\", \"latitude\": 37.7749, \"longitude\": -122.4194},\n",
    "    {\"name\": \"New York City\", \"latitude\": 40.7128, \"longitude\": -74.0060},\n",
    "    {\"name\": \"Los Angeles\", \"latitude\": 34.0522, \"longitude\": -118.2437},\n",
    "    {\"name\": \"Chicago\", \"latitude\": 41.8781, \"longitude\": -87.6298},\n",
    "    {\"name\": \"Miami\", \"latitude\": 25.7617, \"longitude\": -80.1918}\n",
    "]\n",
    "\n",
    "def get_weather_data(city_name):\n",
    "    # Find the city object by name\n",
    "    city = next((c for c in cities if c[\"name\"] == city_name), None)\n",
    "\n",
    "    # If city is found, get the weather data using its coordinates\n",
    "    if city:\n",
    "        # Construct the URL based on the city's latitude and longitude\n",
    "        url = f\"https://api.weather.gov/points/{city['latitude']},{city['longitude']}\"\n",
    "\n",
    "        # Make a request to the URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "\n",
    "        # Ensure the response status is 200 (OK)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # Extracting the forecast URL from the response\n",
    "            forecast_url = data[\"properties\"][\"forecast\"]\n",
    "\n",
    "            # Fetch the actual forecast data using the extracted URL\n",
    "            forecast_response = requests.get(forecast_url)\n",
    "\n",
    "            if forecast_response.status_code == 200:\n",
    "                forecast_data = forecast_response.json()\n",
    "                tonight_forecast = forecast_data['properties']['periods'][0]\n",
    "\n",
    "                # Display the forecast\n",
    "                return tonight_forecast['detailedForecast']\n",
    "            else:\n",
    "                print(f\"Error fetching forecast data. HTTP Status Code: {forecast_response.status_code}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error fetching grid point data. HTTP Status Code: {response.status_code}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"City '{city_name}' not found in the list.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Function Definitions 🔄\n",
    "\n",
    "We're setting up the `get_weather_data` function. Similar to what we did with the balloon launcher, this allows ChatGPT to fetch weather details for select cities based on the given parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [{\n",
    "    \"name\": \"get_weather_data\",\n",
    "    \"description\": \"This function can get weather information for some of the US's largest cities\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"San Francisco\", \"New York City\", \"Los Angeles\", \"Chicago\", \"Miami\"],\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"city_name\"],\n",
    "    },\n",
    "}]\n",
    "available_functions = {\n",
    "    \"get_weather_data\": get_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refreshing the `converse` Function 🔄\n",
    "\n",
    "We've tweaked our main conversation handler, `converse`, to account for the new weather-fetching capability. It now understands how to work with the `get_weather_data` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def converse(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    \n",
    "    messages.append(response_message) \n",
    "    if response_message.get(\"function_call\"):\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        print('[inspector] Oh, we got a function call! 🔨')\n",
    "        print('[inspector] ===> function_name', function_name)\n",
    "        print('[inspector] ===> function_args', function_args)\n",
    "        function_response = function_to_call(\n",
    "            city_name=function_args.get(\"city_name\"),\n",
    "        )\n",
    "        print('[inspector] ===> function_response', function_response)\n",
    "\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print('Assistant: ', function_response)\n",
    "        \n",
    "    else: \n",
    "        content = response_message.get(\"content\")\n",
    "        print('Assistant: ', content)\n",
    "\n",
    "    \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatting with ChatGPT: Let's Talk Weather! ☔🌞\n",
    "\n",
    "Initiate another conversation with ChatGPT! This time, you can ask about real-time weather data for some of the major US cities. Experience the dynamic function calling in action!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "message_count = 0 \n",
    "while message_count < 10: \n",
    "    user_input = input(\"User: \")\n",
    "    user_message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages.append(user_message)\n",
    "    converse(messages)\n",
    "    message_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion 🎉\n",
    "\n",
    "Congratulations on completing this interactive tutorial on OpenAI's function calling with ChatGPT! You've successfully learned how to integrate dynamic function calls into your conversations with ChatGPT, empowering it to \"act\" based on your code and provide more dynamic responses.\n",
    "\n",
    "If you found this Colab notebook useful and would like to see more content like this, consider following me on Twitter. \n",
    "\n",
    "🐦 [Follow Josh Bickett on Twitter](https://twitter.com/josh_bickett)\n",
    "\n",
    "I also share software tutorials and LLM content on YouTube. \n",
    "\n",
    "🎥 [Subscribe to Josh Bickett on YouTube](https://www.youtube.com/@joshbickett)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
