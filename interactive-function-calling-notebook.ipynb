{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive OpenAI Function Calling Tutorial\n",
    "\n",
    "Learn by doing! This interactive tutorial lets you run function calling code to see how it works. The code is easy to modify. Feel free to use this as a base to build your own functions!\n",
    "\n",
    "Creator: [Josh Bickett](https://twitter.com/josh_bickett)\n",
    "\n",
    "Colab: [Interactive Notebook](https://colab.research.google.com/github/joshbickett/function-calling-notebook/blob/main/interactive-function-calling-notebook.ipynb)\n",
    "\n",
    "Github: [Interactive Notebook](https://github.com/joshbickett/function-calling-notebook)\n",
    "\n",
    "## What is a Function?\n",
    "\n",
    "Functions let ChatGPT do things in the real world.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import openai\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = 'YOUR_API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def launch_water_balloon(balloon_size):\n",
    "    hit_locations = ['the ground', 'a tree', 'the moon']\n",
    "    random_location = random.choice(hit_locations)\n",
    "    launch_results = f'Launching the {balloon_size} water balloon, it hit {random_location}!'\n",
    "    return launch_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"launch_water_balloon\",\n",
    "        \"description\": \"This function launches a hypothetical water balloon\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"balloon_size\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"Large\", \"Medium\", \"Small\"],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"balloon_size\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "available_functions = {\n",
    "    \"launch_water_balloon\": launch_water_balloon,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSPECT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def converse(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    \n",
    "    messages.append(response_message) \n",
    "    if response_message.get(\"function_call\"):\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if INSPECT:\n",
    "          print('[inspector] Oh, we got a function call! ðŸ”¨')\n",
    "          print('[inspector] ===> function_name', function_name)\n",
    "          print('[inspector] ===> function_args', function_args)\n",
    "        function_response = function_to_call(\n",
    "            balloon_size=function_args.get(\"balloon_size\"),\n",
    "        )\n",
    "        if INSPECT:\n",
    "          print('[inspector] ===> function_response', function_response)\n",
    "\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print('Assistant: ', function_response)\n",
    "        \n",
    "    else: \n",
    "        content = response_message.get(\"content\")\n",
    "        print('Assistant: ', content)\n",
    "\n",
    "    \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "message_count = 0 \n",
    "while message_count < 10: \n",
    "    user_input = input(\"User: \")\n",
    "    user_message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages.append(user_message)\n",
    "    converse(messages)\n",
    "    message_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cities = [\n",
    "    {\"name\": \"San Francisco\", \"latitude\": 37.7749, \"longitude\": -122.4194},\n",
    "    {\"name\": \"New York City\", \"latitude\": 40.7128, \"longitude\": -74.0060},\n",
    "    {\"name\": \"Los Angeles\", \"latitude\": 34.0522, \"longitude\": -118.2437},\n",
    "    {\"name\": \"Chicago\", \"latitude\": 41.8781, \"longitude\": -87.6298},\n",
    "    {\"name\": \"Miami\", \"latitude\": 25.7617, \"longitude\": -80.1918}\n",
    "]\n",
    "\n",
    "def get_weather_data(city_name):\n",
    "    # Find the city object by name\n",
    "    city = next((c for c in cities if c[\"name\"] == city_name), None)\n",
    "\n",
    "    # If city is found, get the weather data using its coordinates\n",
    "    if city:\n",
    "        # Construct the URL based on the city's latitude and longitude\n",
    "        url = f\"https://api.weather.gov/points/{city['latitude']},{city['longitude']}\"\n",
    "\n",
    "        # Make a request to the URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "\n",
    "        # Ensure the response status is 200 (OK)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # Extracting the forecast URL from the response\n",
    "            forecast_url = data[\"properties\"][\"forecast\"]\n",
    "\n",
    "            # Fetch the actual forecast data using the extracted URL\n",
    "            forecast_response = requests.get(forecast_url)\n",
    "\n",
    "            if forecast_response.status_code == 200:\n",
    "                forecast_data = forecast_response.json()\n",
    "                tonight_forecast = forecast_data['properties']['periods'][0]\n",
    "\n",
    "                # Display the forecast\n",
    "                return tonight_forecast['detailedForecast']\n",
    "            else:\n",
    "                print(f\"Error fetching forecast data. HTTP Status Code: {forecast_response.status_code}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Error fetching grid point data. HTTP Status Code: {response.status_code}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"City '{city_name}' not found in the list.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [{\n",
    "    \"name\": \"get_weather_data\",\n",
    "    \"description\": \"This function can get weather information for some of the US's largest cities\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city_name\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"San Francisco\", \"New York City\", \"Los Angeles\", \"Chicago\", \"Miami\"],\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"city_name\"],\n",
    "    },\n",
    "}]\n",
    "available_functions = {\n",
    "    \"get_weather_data\": get_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def converse(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "    \n",
    "    \n",
    "    messages.append(response_message) \n",
    "    if response_message.get(\"function_call\"):\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if INSPECT:\n",
    "          print('[inspector] Oh, we got a function call! ðŸ”¨')\n",
    "          print('[inspector] ===> function_name', function_name)\n",
    "          print('[inspector] ===> function_args', function_args)\n",
    "        function_response = function_to_call(\n",
    "            city_name=function_args.get(\"city_name\"),\n",
    "        )\n",
    "        if INSPECT:\n",
    "          print('[inspector] ===> function_response', function_response)\n",
    "\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print('Assistant: ', function_response)\n",
    "        \n",
    "    else: \n",
    "        content = response_message.get(\"content\")\n",
    "        print('Assistant: ', content)\n",
    "\n",
    "    \n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "message_count = 0 \n",
    "while message_count < 10: \n",
    "    user_input = input(\"User: \")\n",
    "    user_message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages.append(user_message)\n",
    "    converse(messages)\n",
    "    message_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
